<template>
  <div class="video-display">
    <!-- ä¸»è§†é¢‘çª—å£ (å¯¹æ–¹ç”»é¢) -->
    <VideoWindow
      ref="remoteWindowRef"
      :stream="remoteStream"
      :autoplay="true"
      :muted="false"
      :mirror="false"
      placeholder-icon="ğŸ“¹"
      placeholder-text="ç­‰å¾…å¯¹æ–¹åŠ å…¥..."
    >
      <!-- é¡¶éƒ¨çŠ¶æ€æ  -->
      <template #overlay>
        <div class="status-bar">
          <span class="status-item">
            <span class="status-dot" :class="{ active: isConnected }"></span>
            {{ isConnected ? 'å·²è¿æ¥' : 'æœªè¿æ¥' }}
          </span>
          <span class="status-item" v-if="duration">
            â±ï¸ {{ formatDuration(duration) }}
          </span>
        </div>
      </template>

      <!-- è‡ªå®šä¹‰å†…å®¹: äººè„¸è¯†åˆ«æ¡†ç­‰ -->
      <template #content>
        <slot name="remote-content"></slot>
      </template>
    </VideoWindow>

    <!-- æœ¬åœ°è§†é¢‘å°çª— (è‡ªå·±çš„ç”»é¢) -->
    <div class="local-video-wrapper">
      <VideoWindow
        ref="localWindowRef"
        :stream="localVideoStream"
        :autoplay="true"
        :muted="true"
        :mirror="true"
        :is-small="true"
        placeholder-icon="ğŸ‘¤"
        placeholder-text=""
      >
        <!-- æ§åˆ¶æŒ‰é’® -->
        <template #controls>
          <div class="controls">
            <button 
              class="control-btn"
              :class="{ active: isCameraOn }"
              @click="toggleCamera"
              title="æ‘„åƒå¤´"
            >
              {{ isCameraOn ? 'ğŸ“¹' : 'ğŸ“¹âŒ' }}
            </button>
            <button 
              class="control-btn"
              :class="{ active: isMicOn }"
              @click="toggleMic"
              title="éº¦å…‹é£"
            >
              {{ isMicOn ? 'ğŸ¤' : 'ğŸ¤âŒ' }}
            </button>
          </div>
        </template>

        <!-- è‡ªå®šä¹‰å†…å®¹: æœ¬åœ°è§†é¢‘çš„é¢å¤–ä¿¡æ¯ -->
        <template #content>
          <slot name="local-content"></slot>
        </template>
      </VideoWindow>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted, onUnmounted, watch } from 'vue'
import VideoWindow from './VideoWindow.vue'
import { setIntervalAtLeast, type IntervalController } from '../utils'
import { useVoiceRecognition } from '../hooks/useVoiceRecognition'

interface Props {
  /** æ˜¯å¦è‡ªåŠ¨å¯åŠ¨æ‘„åƒå¤´ */
  autoStart?: boolean
}

const props = withDefaults(defineProps<Props>(), {
  autoStart: true
})

const emit = defineEmits<{
  streamReady: [stream: MediaStream]
  streamError: [error: Error]
  // ASR äº‹ä»¶
  asrPartialText: [text: string]
  asrFinalText: [text: string]
  asrSpeechStart: []
  asrSpeechStop: []
}>()

// è§†é¢‘çª—å£å¼•ç”¨
const localWindowRef = ref<InstanceType<typeof VideoWindow> | null>(null)
const remoteWindowRef = ref<InstanceType<typeof VideoWindow> | null>(null)

// åª’ä½“æµ - åˆ†åˆ«ç®¡ç†è§†é¢‘å’ŒéŸ³é¢‘æµ
const localVideoStream = ref<MediaStream | null>(null)  // ä»…è§†é¢‘æµï¼Œä¼ ç»™ VideoWindow
const localAudioStream = ref<MediaStream | null>(null)  // ä»…éŸ³é¢‘æµï¼Œç”¨äºé€šè¯
const remoteStream = ref<MediaStream | null>(null)

// æ§åˆ¶çŠ¶æ€
const isCameraOn = ref(false)
const isMicOn = ref(false)
const isConnected = ref(false)
const duration = ref(0)

// äººè„¸è¯†åˆ«ç›¸å…³
const recognitionGap = ref(1000) // é»˜è®¤ 1 ç§’
const localFaces = ref<any[]>([])

let durationInterval: number | null = null
let recognitionController: IntervalController | null = null

const API_BASE_URL = 'http://localhost:8000'

// è¯­éŸ³è¯†åˆ«ç›¸å…³ - ä½¿ç”¨æ•´åˆçš„ Hook
const {
  isActive: voiceRecognitionActive,
  isRecording: voiceRecording,
  asrConnected,
  asrConnecting,
  asrSessionId,
  asrError,
  recorderError,
  start: startVoiceRecognition,
  stop: stopVoiceRecognition
} = useVoiceRecognition({
  asrUrl: 'ws://localhost:8000/api/sr/realtime',
  sampleRate: 16000,
  bufferSize: 4096,
  autoReconnect: true,
  verbose: true,
  // ASR äº‹ä»¶å›è°ƒ
  onPartialText: (text: string) => {
    emit('asrPartialText', text)
  },
  onFinalText: (text: string) => {
    emit('asrFinalText', text)
  },
  onSpeechStart: () => {
    emit('asrSpeechStart')
  },
  onSpeechStop: () => {
    emit('asrSpeechStop')
  },
  onConnected: (sessionId: string) => {
  },
  onError: (error: string) => {
  }
})

/**
 * å¯åŠ¨æœ¬åœ°æ‘„åƒå¤´å’Œéº¦å…‹é£
 */
const startCamera = async () => {
  try {
    // 1. è·å–è§†é¢‘æµï¼ˆä»…æ‘„åƒå¤´ï¼‰
    const videoStream = await navigator.mediaDevices.getUserMedia({
      video: {
        width: { ideal: 1280 },
        height: { ideal: 720 },
        facingMode: 'user'
      },
      audio: false  // ä¸åŒ…å«éŸ³é¢‘
    })

    localVideoStream.value = videoStream
    isCameraOn.value = true

    // 2. è·å–éŸ³é¢‘æµï¼ˆä»…éº¦å…‹é£ï¼‰
    try {
      const audioStream = await navigator.mediaDevices.getUserMedia({
        video: false,  // ä¸åŒ…å«è§†é¢‘
        audio: true
      })

      localAudioStream.value = audioStream
      isMicOn.value = true
    } catch (audioError) {
      console.warn('éº¦å…‹é£å¯åŠ¨å¤±è´¥:', audioError)
      // å³ä½¿éº¦å…‹é£å¤±è´¥ï¼Œæ‘„åƒå¤´ä»å¯ä½¿ç”¨
    }

    emit('streamReady', videoStream)
  } catch (error) {
    console.error('å¯åŠ¨æ‘„åƒå¤´å¤±è´¥:', error)
    emit('streamError', error as Error)
  }
}

/**
 * åœæ­¢æœ¬åœ°æ‘„åƒå¤´å’Œéº¦å…‹é£
 */
const stopCamera = () => {
  // åœæ­¢è§†é¢‘æµ
  if (localVideoStream.value) {
    localVideoStream.value.getTracks().forEach(track => track.stop())
    localVideoStream.value = null
  }

  // åœæ­¢éŸ³é¢‘æµ
  if (localAudioStream.value) {
    localAudioStream.value.getTracks().forEach(track => track.stop())
    localAudioStream.value = null
  }

  isCameraOn.value = false
  isMicOn.value = false
}

/**
 * åˆ‡æ¢æ‘„åƒå¤´
 */
const toggleCamera = () => {
  if (!localVideoStream.value) {
    startCamera()
    return
  }

  const videoTrack = localVideoStream.value.getVideoTracks()[0]
  if (videoTrack) {
    videoTrack.enabled = !videoTrack.enabled
    isCameraOn.value = videoTrack.enabled
  }
}

/**
 * åˆ‡æ¢éº¦å…‹é£
 */
const toggleMic = () => {
  if (!localAudioStream.value) return

  const audioTrack = localAudioStream.value.getAudioTracks()[0]
  if (audioTrack) {
    audioTrack.enabled = !audioTrack.enabled
    isMicOn.value = audioTrack.enabled
  }
}

/**
 * ç›‘å¬éº¦å…‹é£çŠ¶æ€ï¼Œè‡ªåŠ¨å¯åŠ¨/åœæ­¢è¯­éŸ³è¯†åˆ«
 */
watch(isMicOn, (newValue) => {
  if (newValue && localAudioStream.value) {
    // éº¦å…‹é£æ‰“å¼€æ—¶å¯åŠ¨è¯­éŸ³è¯†åˆ«
    startVoiceRecognition(localAudioStream.value)
  } else {
    // éº¦å…‹é£å…³é—­æ—¶åœæ­¢è¯­éŸ³è¯†åˆ«
    stopVoiceRecognition()
  }
})

/**
 * è®¾ç½®è¿œç¨‹è§†é¢‘æµ
 */
const setRemoteStream = (stream: MediaStream) => {
  remoteStream.value = stream
  isConnected.value = true
  startDurationTimer()
}

/**
 * å¼€å§‹è®¡æ—¶
 */
const startDurationTimer = () => {
  if (durationInterval) return
  
  duration.value = 0
  durationInterval = window.setInterval(() => {
    duration.value++
  }, 1000)
}

/**
 * åœæ­¢è®¡æ—¶
 */
const stopDurationTimer = () => {
  if (durationInterval) {
    clearInterval(durationInterval)
    durationInterval = null
  }
  duration.value = 0
}

/**
 * æ ¼å¼åŒ–æ—¶é•¿
 */
const formatDuration = (seconds: number): string => {
  const hrs = Math.floor(seconds / 3600)
  const mins = Math.floor((seconds % 3600) / 60)
  const secs = seconds % 60

  if (hrs > 0) {
    return `${hrs.toString().padStart(2, '0')}:${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }
  return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
}

/**
 * è·å–è¯†åˆ«é—´éš”æ—¶é—´
 */
const fetchRecognitionGap = async () => {
  try {
    const response = await fetch(`${API_BASE_URL}/api/cv/recognition-gap`)
    const data = await response.json()
    recognitionGap.value = data.recognition_gap || 1000
    console.log('è¯†åˆ«é—´éš”:', recognitionGap.value, 'ms')
  } catch (error) {
    console.error('è·å–è¯†åˆ«é—´éš”å¤±è´¥:', error)
    recognitionGap.value = 1000 // ä½¿ç”¨é»˜è®¤å€¼
  }
}

/**
 * è°ƒç”¨äººè„¸è¯†åˆ« API
 */
const recognizeFaces = async () => {
  if (!localWindowRef.value) return
  
  try {
    // ä»è§†é¢‘æ•è·å½“å‰å¸§
    const blob = await localWindowRef.value.captureFrameAsync()
    if (!blob) return
    
    // åˆ›å»º FormData
    const formData = new FormData()
    formData.append('file', blob, 'frame.jpg')
    
    // è°ƒç”¨è¯†åˆ« API
    const response = await fetch(`${API_BASE_URL}/api/cv/recognize-faces`, {
      method: 'POST',
      body: formData
    })
    
    if (!response.ok) {
      console.error('è¯†åˆ«å¤±è´¥:', response.statusText)
      return
    }
    
    const data = await response.json()
    console.log('ğŸ“¸ äººè„¸è¯†åˆ«ç»“æœ:', data)
    
    // æ›´æ–°äººè„¸æ•°æ®
    if (data.faces && data.faces.length > 0) {
      localFaces.value = data.faces
      // console.log(`âœ“ æ£€æµ‹åˆ° ${data.faces.length} ä¸ªäººè„¸ï¼Œå¼€å§‹ç»˜åˆ¶...`)
      
      // åœ¨ Canvas ä¸Šç»˜åˆ¶äººè„¸æ¡†
      localWindowRef.value.drawFaces(data.faces)
    } else {
      // æ²¡æœ‰æ£€æµ‹åˆ°äººè„¸,æ¸…ç©º Canvas
      console.log('â„¹ï¸  æœªæ£€æµ‹åˆ°äººè„¸')
      localFaces.value = []
      localWindowRef.value.clearCanvas()
    }
  } catch (error) {
    console.error('äººè„¸è¯†åˆ«å‡ºé”™:', error)
  }
}

/**
 * å¯åŠ¨äººè„¸è¯†åˆ«å®šæ—¶å™¨
 */
const startFaceRecognition = () => {
  // å¦‚æœå·²ç»åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢
  if (recognitionController?.isRunning()) {
    console.log('äººè„¸è¯†åˆ«å·²åœ¨è¿è¡Œï¼Œè·³è¿‡å¯åŠ¨')
    return
  }
  
  console.log('ğŸš€ å¯åŠ¨äººè„¸è¯†åˆ«,é—´éš”:', recognitionGap.value, 'ms')
  
  // ä½¿ç”¨ä¼˜åŒ–çš„å®šæ—¶å™¨ï¼Œç¡®ä¿æ¯æ¬¡è¯†åˆ«å®Œæˆåè‡³å°‘ç­‰å¾…æŒ‡å®šé—´éš”
  recognitionController = setIntervalAtLeast(async () => {
    await recognizeFaces()
  }, recognitionGap.value)
}

/**
 * åœæ­¢äººè„¸è¯†åˆ«å®šæ—¶å™¨
 */
const stopFaceRecognition = () => {
  if (recognitionController) {
    recognitionController.clear()
    recognitionController = null
    console.log('â¹ï¸  åœæ­¢äººè„¸è¯†åˆ«')
  }
  
  // æ¸…ç©ºäººè„¸æ•°æ®å’Œ Canvas
  localFaces.value = []
  if (localWindowRef.value) {
    localWindowRef.value.clearCanvas()
  }
}

onMounted(async () => {
  // è·å–è¯†åˆ«é—´éš”
  await fetchRecognitionGap()
  
  // å¯åŠ¨æ‘„åƒå¤´
  if (props.autoStart) {
    await startCamera()
    
    // ç­‰å¾…è§†é¢‘æµå‡†å¤‡å¥½åå¯åŠ¨äººè„¸è¯†åˆ«
    setTimeout(() => {
      startFaceRecognition()
    }, 1000)
  }
})

onUnmounted(() => {
  stopCamera()
  stopDurationTimer()
  stopFaceRecognition()
  stopVoiceRecognition()
})

// æš´éœ²æ–¹æ³•ç»™çˆ¶ç»„ä»¶
defineExpose({
  startCamera,
  stopCamera,
  toggleCamera,
  toggleMic,
  setRemoteStream,
  getLocalVideoStream: () => localVideoStream.value,
  getLocalAudioStream: () => localAudioStream.value,
  getRemoteStream: () => remoteStream.value,
  startFaceRecognition,
  stopFaceRecognition,
  recognizeFaces,
  // è¯­éŸ³è¯†åˆ«ç›¸å…³
  startVoiceRecognition,
  stopVoiceRecognition,
  voiceRecognitionActive,
  voiceRecording,
  asrConnected,
  asrConnecting,
  asrSessionId,
  asrError,
  recorderError
})
</script>

<style scoped>
.video-display {
  position: relative;
  width: 100%;
  height: 100%;
  background: #1a1a1a;
  border-radius: 8px;
  overflow: hidden;
}

/* æœ¬åœ°è§†é¢‘å°çª—ä½ç½® */
.local-video-wrapper {
  position: absolute;
  bottom: 20px;
  right: 20px;
  width: 240px;
  height: 180px;
  z-index: 100;
}

/* çŠ¶æ€æ æ ·å¼ */
.status-bar {
  margin: 16px;
  display: inline-flex;
  gap: 16px;
  padding: 8px 16px;
  background: rgba(0, 0, 0, 0.6);
  border-radius: 20px;
  backdrop-filter: blur(10px);
  font-size: 14px;
  color: #fff;
}

.status-item {
  display: flex;
  align-items: center;
  gap: 6px;
}

.status-dot {
  width: 8px;
  height: 8px;
  border-radius: 50%;
  background: #666;
  transition: background 0.3s ease;
}

.status-dot.active {
  background: #22c55e;
  box-shadow: 0 0 8px #22c55e;
}

/* æ§åˆ¶æŒ‰é’®æ ·å¼ */
.controls {
  display: flex;
  gap: 8px;
  justify-content: center;
  padding: 8px;
  opacity: 0;
  transition: opacity 0.3s ease;
}

.local-video-wrapper:hover .controls {
  opacity: 1;
}

.control-btn {
  width: 36px;
  height: 36px;
  border-radius: 50%;
  border: none;
  background: rgba(0, 0, 0, 0.7);
  color: white;
  font-size: 16px;
  cursor: pointer;
  display: flex;
  align-items: center;
  justify-content: center;
  transition: all 0.2s ease;
  backdrop-filter: blur(10px);
}

.control-btn:hover {
  background: rgba(0, 0, 0, 0.9);
  transform: scale(1.1);
}

.control-btn.active {
  background: rgba(59, 130, 246, 0.8);
}

/* å“åº”å¼è°ƒæ•´ */
@media (max-width: 768px) {
  .local-video-wrapper {
    width: 160px;
    height: 120px;
    bottom: 12px;
    right: 12px;
  }

  .status-bar {
    font-size: 12px;
    padding: 6px 12px;
    margin: 12px;
  }
}
</style>

