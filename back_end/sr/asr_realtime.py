"""
å®æ—¶è¯­éŸ³è¯†åˆ«æ¨¡å—
åŸºäºé˜¿é‡Œäº‘ Dashscope Qwen-Omni æ¨¡å‹
"""
import logging
import os
import base64
import sys
import time
from typing import Optional, Callable, Dict, Any
import dashscope
from dashscope.audio.qwen_omni import *
from dashscope.audio.qwen_omni.omni_realtime import TranscriptionParams

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import model_config


def setup_logging(level=logging.INFO):
    """é…ç½®æ—¥å¿—è¾“å‡º"""
    logger = logging.getLogger('dashscope')
    logger.setLevel(level)
    
    # é¿å…é‡å¤æ·»åŠ  handler
    if not logger.handlers:
        handler = logging.StreamHandler(sys.stdout)
        handler.setLevel(level)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    
    logger.propagate = False
    return logger


def init_api_key():
    """åˆå§‹åŒ– API Key"""
    if not dashscope.api_key:
        dashscope.api_key = model_config.dashscope_api_key

class ASRCallback(OmniRealtimeCallback):
    """
    å®æ—¶è¯­éŸ³è¯†åˆ«å›è°ƒå¤„ç†å™¨
    
    æ”¯æŒè‡ªå®šä¹‰å›è°ƒå‡½æ•°æ¥å¤„ç†è¯†åˆ«ç»“æœ
    """
    def __init__(
        self, 
        conversation=None,
        on_final_text: Optional[Callable[[str], None]] = None,
        on_partial_text: Optional[Callable[[str], None]] = None,
        on_speech_start: Optional[Callable[[], None]] = None,
        on_speech_stop: Optional[Callable[[], None]] = None,
        on_session_created: Optional[Callable[[str], None]] = None,
        on_error: Optional[Callable[[Exception], None]] = None,
        verbose: bool = False
    ):
        """
        åˆå§‹åŒ–å›è°ƒå¤„ç†å™¨
        
        Args:
            conversation: OmniRealtimeConversation å®ä¾‹
            on_final_text: æœ€ç»ˆè¯†åˆ«æ–‡æœ¬çš„å›è°ƒå‡½æ•°
            on_partial_text: éƒ¨åˆ†è¯†åˆ«æ–‡æœ¬çš„å›è°ƒå‡½æ•°
            on_speech_start: è¯­éŸ³å¼€å§‹çš„å›è°ƒå‡½æ•°
            on_speech_stop: è¯­éŸ³åœæ­¢çš„å›è°ƒå‡½æ•°
            on_session_created: ä¼šè¯åˆ›å»ºçš„å›è°ƒå‡½æ•°
            on_error: é”™è¯¯å¤„ç†çš„å›è°ƒå‡½æ•°
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—
        """
        self.conversation = conversation
        self.on_final_text = on_final_text
        self.on_partial_text = on_partial_text
        self.on_speech_start = on_speech_start
        self.on_speech_stop = on_speech_stop
        self.on_session_created = on_session_created
        self.on_error = on_error
        self.verbose = verbose
        
        self.handlers = {
            'session.created': self._handle_session_created,
            'conversation.item.input_audio_transcription.completed': self._handle_final_text,
            'conversation.item.input_audio_transcription.text': self._handle_stash_text,
            'input_audio_buffer.speech_started': self._handle_speech_start,
            'input_audio_buffer.speech_stopped': self._handle_speech_stop,
            'response.done': self._handle_response_done
        }

    def on_open(self):
        if self.verbose:
            print('âœ“ ASR è¿æ¥å·²å»ºç«‹')

    def on_close(self, code, msg):
        if self.verbose:
            print(f'âœ— ASR è¿æ¥å·²å…³é—­, code: {code}, msg: {msg}')

    def on_event(self, response):
        try:
            event_type = response.get('type')
            handler = self.handlers.get(event_type)
            
            if self.verbose:
                print(f"ğŸ“¨ æ”¶åˆ°äº‹ä»¶: {event_type}")
            
            if handler:
                handler(response)
        except Exception as e:
            if self.verbose:
                print(f'âŒ äº‹ä»¶å¤„ç†é”™è¯¯: {e}')
            if self.on_error:
                self.on_error(e)

    def _handle_session_created(self, response):
        session_id = response.get('session', {}).get('id', 'unknown')
        if self.verbose:
            print(f"âœ“ ä¼šè¯å·²åˆ›å»º: {session_id}")
        if self.on_session_created:
            self.on_session_created(session_id)

    def _handle_final_text(self, response):
        text = response.get('transcript', '')
        if self.verbose:
            print(f"ğŸ“ æœ€ç»ˆè¯†åˆ«: {text}")
        if self.on_final_text:
            self.on_final_text(text)

    def _handle_stash_text(self, response):
        text = response.get('stash', '')
        if self.verbose:
            print(f"ğŸ“ éƒ¨åˆ†è¯†åˆ«: {text}")
        if self.on_partial_text:
            self.on_partial_text(text)

    def _handle_speech_start(self, response):
        if self.verbose:
            print('ğŸ¤ è¯­éŸ³å¼€å§‹')
        if self.on_speech_start:
            self.on_speech_start()

    def _handle_speech_stop(self, response):
        if self.verbose:
            print('â¹ï¸  è¯­éŸ³åœæ­¢')
        if self.on_speech_stop:
            self.on_speech_stop()

    def _handle_response_done(self, response):
        if self.verbose and self.conversation:
            print('âœ“ å“åº”å®Œæˆ')
            print(f"[æ€§èƒ½æŒ‡æ ‡] response: {self.conversation.get_last_response_id()}, "
                  f"é¦–ä¸ªæ–‡æœ¬å»¶è¿Ÿ: {self.conversation.get_last_first_text_delay()}, "
                  f"é¦–ä¸ªéŸ³é¢‘å»¶è¿Ÿ: {self.conversation.get_last_first_audio_delay()}")


class RealtimeASR:
    """
    å®æ—¶è¯­éŸ³è¯†åˆ«å°è£…ç±»
    
    æä¾›ç®€å•æ˜“ç”¨çš„ API æ¥è¿›è¡Œå®æ—¶è¯­éŸ³è¯†åˆ«
    """
    def __init__(
        self,
        model: Optional[str] = None,
        url: Optional[str] = None,
        language: str = 'zh',
        sample_rate: int = 16000,
        input_audio_format: str = "pcm",
        verbose: bool = False
    ):
        """
        åˆå§‹åŒ–å®æ—¶è¯­éŸ³è¯†åˆ«
        
        Args:
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹
            url: WebSocket URLï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ URL
            language: è¯­è¨€ï¼Œé»˜è®¤ä¸ºä¸­æ–‡ 'zh'
            sample_rate: é‡‡æ ·ç‡ï¼Œé»˜è®¤ 16000
            input_audio_format: éŸ³é¢‘æ ¼å¼ï¼Œé»˜è®¤ "pcm"
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—
        """
        init_api_key()
        
        self.model = model or model_config.asr_model
        self.url = url or model_config.asr_url
        self.language = language
        self.sample_rate = sample_rate
        self.input_audio_format = input_audio_format
        self.verbose = verbose
        
        self.conversation: Optional[OmniRealtimeConversation] = None
        self.callback: Optional[ASRCallback] = None
        self.is_connected = False
        
        # å­˜å‚¨è¯†åˆ«ç»“æœ
        self.final_texts = []
        self.partial_texts = []
    
    def connect(
        self,
        on_final_text: Optional[Callable[[str], None]] = None,
        on_partial_text: Optional[Callable[[str], None]] = None,
        on_speech_start: Optional[Callable[[], None]] = None,
        on_speech_stop: Optional[Callable[[], None]] = None,
        on_session_created: Optional[Callable[[str], None]] = None,
        on_error: Optional[Callable[[Exception], None]] = None
    ):
        """
        å»ºç«‹è¿æ¥
        
        Args:
            on_final_text: æœ€ç»ˆè¯†åˆ«æ–‡æœ¬çš„å›è°ƒå‡½æ•°
            on_partial_text: éƒ¨åˆ†è¯†åˆ«æ–‡æœ¬çš„å›è°ƒå‡½æ•°
            on_speech_start: è¯­éŸ³å¼€å§‹çš„å›è°ƒå‡½æ•°
            on_speech_stop: è¯­éŸ³åœæ­¢çš„å›è°ƒå‡½æ•°
            on_session_created: ä¼šè¯åˆ›å»ºçš„å›è°ƒå‡½æ•°
            on_error: é”™è¯¯å¤„ç†çš„å›è°ƒå‡½æ•°
        """
        if self.is_connected:
            raise RuntimeError("å·²ç»è¿æ¥ï¼Œè¯·å…ˆæ–­å¼€è¿æ¥")
        
        # åˆ›å»ºå›è°ƒå¤„ç†å™¨
        self.callback = ASRCallback(
            conversation=None,  # ç¨åæ³¨å…¥
            on_final_text=on_final_text or self._default_on_final_text,
            on_partial_text=on_partial_text or self._default_on_partial_text,
            on_speech_start=on_speech_start,
            on_speech_stop=on_speech_stop,
            on_session_created=on_session_created,
            on_error=on_error,
            verbose=self.verbose
        )
        
        # åˆ›å»ºä¼šè¯
        self.conversation = OmniRealtimeConversation(
            model=self.model,
            url=self.url,
            callback=self.callback
        )
        
        # æ³¨å…¥ conversation åˆ° callback
        self.callback.conversation = self.conversation
        
        # å»ºç«‹è¿æ¥
        self.conversation.connect()
        
        # é…ç½®ä¼šè¯å‚æ•°
        transcription_params = TranscriptionParams(
            language=self.language,
            sample_rate=self.sample_rate,
            input_audio_format=self.input_audio_format
        )
        
        self.conversation.update_session(
            output_modalities=[MultiModality.TEXT],
            enable_input_audio_transcription=True,
            transcription_params=transcription_params
        )
        
        self.is_connected = True
        
        if self.verbose:
            print(f"âœ“ ASR å·²è¿æ¥: {self.model}")
    
    def send_audio_chunk(self, audio_data: bytes):
        """
        å‘é€éŸ³é¢‘æ•°æ®å—
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®ï¼ˆbytesï¼‰
        """
        if not self.is_connected or not self.conversation:
            raise RuntimeError("æœªè¿æ¥ï¼Œè¯·å…ˆè°ƒç”¨ connect()")
        
        audio_b64 = base64.b64encode(audio_data).decode('ascii')
        self.conversation.append_audio(audio_b64)
    
    def send_audio_file(self, file_path: str, chunk_size: int = 3200, delay: float = 0.1):
        """
        å‘é€éŸ³é¢‘æ–‡ä»¶
        
        Args:
            file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            chunk_size: æ¯æ¬¡è¯»å–çš„å­—èŠ‚æ•°
            delay: æ¯æ¬¡å‘é€çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        if self.verbose:
            print(f"ğŸ“¤ å¼€å§‹å‘é€éŸ³é¢‘æ–‡ä»¶: {file_path}")
        
        with open(file_path, 'rb') as f:
            while chunk := f.read(chunk_size):
                self.send_audio_chunk(chunk)
                time.sleep(delay)
        
        if self.verbose:
            print("âœ“ éŸ³é¢‘æ–‡ä»¶å‘é€å®Œæˆ")
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.conversation:
            self.conversation.close()
            self.is_connected = False
            if self.verbose:
                print("âœ“ ASR è¿æ¥å·²å…³é—­")
    
    def get_final_texts(self) -> list:
        """è·å–æ‰€æœ‰æœ€ç»ˆè¯†åˆ«æ–‡æœ¬"""
        return self.final_texts.copy()
    
    def get_partial_texts(self) -> list:
        """è·å–æ‰€æœ‰éƒ¨åˆ†è¯†åˆ«æ–‡æœ¬"""
        return self.partial_texts.copy()
    
    def clear_results(self):
        """æ¸…ç©ºè¯†åˆ«ç»“æœ"""
        self.final_texts.clear()
        self.partial_texts.clear()
    
    def _default_on_final_text(self, text: str):
        """é»˜è®¤çš„æœ€ç»ˆæ–‡æœ¬å¤„ç†"""
        self.final_texts.append(text)
    
    def _default_on_partial_text(self, text: str):
        """é»˜è®¤çš„éƒ¨åˆ†æ–‡æœ¬å¤„ç†"""
        self.partial_texts.append(text)
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.close()


def read_audio_chunks(file_path: str, chunk_size: int = 3200):
    """
    æŒ‰å—è¯»å–éŸ³é¢‘æ–‡ä»¶
    
    Args:
        file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        chunk_size: æ¯æ¬¡è¯»å–çš„å­—èŠ‚æ•°
        
    Yields:
        éŸ³é¢‘æ•°æ®å—
    """
    with open(file_path, 'rb') as f:
        while chunk := f.read(chunk_size):
            yield chunk


def main():
    """
    å‘½ä»¤è¡Œæµ‹è¯•å…¥å£
    """
    import signal
    
    setup_logging(logging.DEBUG)
    
    audio_file_path = os.path.join(os.path.dirname(__file__), "res/test.pcm")
    
    if not os.path.exists(audio_file_path):
        print(f"âŒ æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file_path}")
        return
    
    print("=" * 60)
    print("å®æ—¶è¯­éŸ³è¯†åˆ«æµ‹è¯•")
    print("=" * 60)
    
    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨ç®¡ç†è¿æ¥
    with RealtimeASR(verbose=True) as asr:
        # è®¾ç½®é€€å‡ºå¤„ç†
        def handle_exit(sig, frame):
            print('\nâš ï¸  Ctrl+C æŒ‰ä¸‹ï¼Œæ­£åœ¨é€€å‡º...')
            asr.close()
            sys.exit(0)
        
        signal.signal(signal.SIGINT, handle_exit)
        
        # å»ºç«‹è¿æ¥
        asr.connect()
        
        # å‘é€éŸ³é¢‘æ–‡ä»¶
        try:
            asr.send_audio_file(audio_file_path)
            time.sleep(3)  # ç­‰å¾…å“åº”
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
        
        # è·å–è¯†åˆ«ç»“æœ
        final_texts = asr.get_final_texts()
        print("\n" + "=" * 60)
        print("è¯†åˆ«ç»“æœæ±‡æ€»:")
        print("=" * 60)
        for i, text in enumerate(final_texts, 1):
            print(f"{i}. {text}")
        print("=" * 60)


if __name__ == '__main__':
    main()